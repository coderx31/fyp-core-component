{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T03:06:42.904664Z",
     "start_time": "2024-03-29T03:06:39.115024Z"
    }
   },
   "id": "3ff065f5f4941b7b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "              0         1         2         3         4         5         6  \\\n0      0.274579  0.560966  0.521340  0.539612  0.584370  0.566328  0.590016   \n1      0.416943  0.780868  0.788520  0.810166  0.835733  0.828571  0.739328   \n2      0.224011  0.632741  0.648564  0.645445  0.590219  0.481998  0.450006   \n3      0.216470  0.588893  0.532681  0.540489  0.593834  0.576432  0.591428   \n4      0.223300  0.554488  0.512918  0.482543  0.464256  0.425962  0.413757   \n...         ...       ...       ...       ...       ...       ...       ...   \n46147  0.060750  0.636769  0.585038  0.652742  0.616112  0.717962  0.669722   \n46148  0.041161  0.751996  0.618682  0.534846  0.539487  0.630493  0.528285   \n46149  0.300101  0.890704  0.812318  0.779347  0.788816  0.798159  0.654105   \n46150  0.045441  0.546909  0.739436  0.626243  0.529209  0.527069  0.618814   \n46151  0.046736  0.700207  0.599806  0.552190  0.578305  0.690314  0.534066   \n\n              7         8         9  ...       173       174        175  \\\n0      0.542824  0.542918  0.595936  ... -5.963057 -3.072044  -5.011403   \n1      0.689585  0.714463  0.779047  ... -3.392732 -2.344621  -3.281808   \n2      0.496442  0.509890  0.603403  ... -0.533864 -7.908329  -3.536236   \n3      0.558195  0.569552  0.616729  ... -6.407280 -4.029168  -5.764251   \n4      0.410311  0.429979  0.477790  ... -8.284494  1.015495  -6.648326   \n...         ...       ...       ...  ...       ...       ...        ...   \n46147  0.610102  0.653336  0.713311  ... -7.802677  9.156364 -10.524547   \n46148  0.520108  0.672241  0.719681  ... -6.086152  4.849677 -15.761593   \n46149  0.659761  0.782625  0.764981  ... -3.452307 -3.107889  -2.995228   \n46150  0.524002  0.501906  0.658899  ...  3.004317 -5.297758  -8.082297   \n46151  0.526542  0.669034  0.687427  ... -5.598451  4.318657 -15.735107   \n\n             176        177        178        179       180        181  \\\n0      -5.808564  -4.776329  -1.666140  -6.362252 -5.209133  -1.626034   \n1      -2.752456  -1.234239  -1.442518  -2.517537 -2.682515  -1.980154   \n2      -5.696254  -2.378804  -7.909769   2.263980 -1.307509   0.180049   \n3      -6.581980  -4.459784  -1.555337  -6.031616 -5.524695  -1.640235   \n4      -6.796526  -3.946552  -6.189187  -2.909742 -4.325276  -4.083507   \n...          ...        ...        ...        ...       ...        ...   \n46147  11.523617 -21.769642  11.141151 -14.523054  5.984777  -5.345934   \n46148   9.697728 -16.421173   6.792037 -13.683490  5.655865 -10.450261   \n46149  -2.873970  -2.793679  -4.259409  -3.905076 -2.975534  -4.176648   \n46150   3.791116 -12.532305   4.468070 -12.664186  7.091371 -15.475475   \n46151  10.823731 -16.819969   5.606885 -14.229694  6.123990 -10.601107   \n\n        labels  \n0        angry  \n1        angry  \n2        angry  \n3        angry  \n4         fear  \n...        ...  \n46147  neutral  \n46148  neutral  \n46149  neutral  \n46150  neutral  \n46151  neutral  \n\n[46152 rows x 183 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>173</th>\n      <th>174</th>\n      <th>175</th>\n      <th>176</th>\n      <th>177</th>\n      <th>178</th>\n      <th>179</th>\n      <th>180</th>\n      <th>181</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.274579</td>\n      <td>0.560966</td>\n      <td>0.521340</td>\n      <td>0.539612</td>\n      <td>0.584370</td>\n      <td>0.566328</td>\n      <td>0.590016</td>\n      <td>0.542824</td>\n      <td>0.542918</td>\n      <td>0.595936</td>\n      <td>...</td>\n      <td>-5.963057</td>\n      <td>-3.072044</td>\n      <td>-5.011403</td>\n      <td>-5.808564</td>\n      <td>-4.776329</td>\n      <td>-1.666140</td>\n      <td>-6.362252</td>\n      <td>-5.209133</td>\n      <td>-1.626034</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.416943</td>\n      <td>0.780868</td>\n      <td>0.788520</td>\n      <td>0.810166</td>\n      <td>0.835733</td>\n      <td>0.828571</td>\n      <td>0.739328</td>\n      <td>0.689585</td>\n      <td>0.714463</td>\n      <td>0.779047</td>\n      <td>...</td>\n      <td>-3.392732</td>\n      <td>-2.344621</td>\n      <td>-3.281808</td>\n      <td>-2.752456</td>\n      <td>-1.234239</td>\n      <td>-1.442518</td>\n      <td>-2.517537</td>\n      <td>-2.682515</td>\n      <td>-1.980154</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.224011</td>\n      <td>0.632741</td>\n      <td>0.648564</td>\n      <td>0.645445</td>\n      <td>0.590219</td>\n      <td>0.481998</td>\n      <td>0.450006</td>\n      <td>0.496442</td>\n      <td>0.509890</td>\n      <td>0.603403</td>\n      <td>...</td>\n      <td>-0.533864</td>\n      <td>-7.908329</td>\n      <td>-3.536236</td>\n      <td>-5.696254</td>\n      <td>-2.378804</td>\n      <td>-7.909769</td>\n      <td>2.263980</td>\n      <td>-1.307509</td>\n      <td>0.180049</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.216470</td>\n      <td>0.588893</td>\n      <td>0.532681</td>\n      <td>0.540489</td>\n      <td>0.593834</td>\n      <td>0.576432</td>\n      <td>0.591428</td>\n      <td>0.558195</td>\n      <td>0.569552</td>\n      <td>0.616729</td>\n      <td>...</td>\n      <td>-6.407280</td>\n      <td>-4.029168</td>\n      <td>-5.764251</td>\n      <td>-6.581980</td>\n      <td>-4.459784</td>\n      <td>-1.555337</td>\n      <td>-6.031616</td>\n      <td>-5.524695</td>\n      <td>-1.640235</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.223300</td>\n      <td>0.554488</td>\n      <td>0.512918</td>\n      <td>0.482543</td>\n      <td>0.464256</td>\n      <td>0.425962</td>\n      <td>0.413757</td>\n      <td>0.410311</td>\n      <td>0.429979</td>\n      <td>0.477790</td>\n      <td>...</td>\n      <td>-8.284494</td>\n      <td>1.015495</td>\n      <td>-6.648326</td>\n      <td>-6.796526</td>\n      <td>-3.946552</td>\n      <td>-6.189187</td>\n      <td>-2.909742</td>\n      <td>-4.325276</td>\n      <td>-4.083507</td>\n      <td>fear</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>46147</th>\n      <td>0.060750</td>\n      <td>0.636769</td>\n      <td>0.585038</td>\n      <td>0.652742</td>\n      <td>0.616112</td>\n      <td>0.717962</td>\n      <td>0.669722</td>\n      <td>0.610102</td>\n      <td>0.653336</td>\n      <td>0.713311</td>\n      <td>...</td>\n      <td>-7.802677</td>\n      <td>9.156364</td>\n      <td>-10.524547</td>\n      <td>11.523617</td>\n      <td>-21.769642</td>\n      <td>11.141151</td>\n      <td>-14.523054</td>\n      <td>5.984777</td>\n      <td>-5.345934</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>46148</th>\n      <td>0.041161</td>\n      <td>0.751996</td>\n      <td>0.618682</td>\n      <td>0.534846</td>\n      <td>0.539487</td>\n      <td>0.630493</td>\n      <td>0.528285</td>\n      <td>0.520108</td>\n      <td>0.672241</td>\n      <td>0.719681</td>\n      <td>...</td>\n      <td>-6.086152</td>\n      <td>4.849677</td>\n      <td>-15.761593</td>\n      <td>9.697728</td>\n      <td>-16.421173</td>\n      <td>6.792037</td>\n      <td>-13.683490</td>\n      <td>5.655865</td>\n      <td>-10.450261</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>46149</th>\n      <td>0.300101</td>\n      <td>0.890704</td>\n      <td>0.812318</td>\n      <td>0.779347</td>\n      <td>0.788816</td>\n      <td>0.798159</td>\n      <td>0.654105</td>\n      <td>0.659761</td>\n      <td>0.782625</td>\n      <td>0.764981</td>\n      <td>...</td>\n      <td>-3.452307</td>\n      <td>-3.107889</td>\n      <td>-2.995228</td>\n      <td>-2.873970</td>\n      <td>-2.793679</td>\n      <td>-4.259409</td>\n      <td>-3.905076</td>\n      <td>-2.975534</td>\n      <td>-4.176648</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>46150</th>\n      <td>0.045441</td>\n      <td>0.546909</td>\n      <td>0.739436</td>\n      <td>0.626243</td>\n      <td>0.529209</td>\n      <td>0.527069</td>\n      <td>0.618814</td>\n      <td>0.524002</td>\n      <td>0.501906</td>\n      <td>0.658899</td>\n      <td>...</td>\n      <td>3.004317</td>\n      <td>-5.297758</td>\n      <td>-8.082297</td>\n      <td>3.791116</td>\n      <td>-12.532305</td>\n      <td>4.468070</td>\n      <td>-12.664186</td>\n      <td>7.091371</td>\n      <td>-15.475475</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>46151</th>\n      <td>0.046736</td>\n      <td>0.700207</td>\n      <td>0.599806</td>\n      <td>0.552190</td>\n      <td>0.578305</td>\n      <td>0.690314</td>\n      <td>0.534066</td>\n      <td>0.526542</td>\n      <td>0.669034</td>\n      <td>0.687427</td>\n      <td>...</td>\n      <td>-5.598451</td>\n      <td>4.318657</td>\n      <td>-15.735107</td>\n      <td>10.823731</td>\n      <td>-16.819969</td>\n      <td>5.606885</td>\n      <td>-14.229694</td>\n      <td>6.123990</td>\n      <td>-10.601107</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n<p>46152 rows Ã— 183 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_df = pd.read_csv('emotion_features.csv', index_col=0)\n",
    "emotion_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T03:06:44.758145Z",
     "start_time": "2024-03-29T03:06:43.989676Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def extract_features_for_model(emotion_features_df):\n",
    "    labels = emotion_features_df['labels']\n",
    "    label_mapping = {\n",
    "        'angry': 0,\n",
    "        'fear': 1,\n",
    "        'disgust': 2,\n",
    "        'sad': 3,\n",
    "        'happy': 4,\n",
    "        'neutral': 5\n",
    "    }\n",
    "    \n",
    "    numerical_labels = labels.map(label_mapping)\n",
    "    emotion_features_df['labels'] = numerical_labels\n",
    "    \n",
    "    x = emotion_features_df.iloc[: ,:-1].values\n",
    "    y = emotion_features_df['labels'].values\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0, shuffle=True)\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    x_train = np.expand_dims(x_train, axis=2)\n",
    "    x_test = np.expand_dims(x_test, axis=2)\n",
    "    joblib.dump(scaler, 'scaler.bin', compress=True)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T03:06:47.378180Z",
     "start_time": "2024-03-29T03:06:47.369101Z"
    }
   },
   "id": "9632055047c62e9"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, filters, kernel_size, dropout):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters, kernel_size=kernel_size, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters * 2, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters * 4, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer = 'adam' , loss = 'sparse_categorical_crossentropy' , metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T03:06:48.176101Z",
     "start_time": "2024-03-29T03:06:48.168549Z"
    }
   },
   "id": "d0e196438e4d5cf8"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "((36921, 182, 1), (36921,), (9231, 182, 1), (9231,))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = extract_features_for_model(emotion_df)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T03:07:22.044243Z",
     "start_time": "2024-03-29T03:07:21.943844Z"
    }
   },
   "id": "35411884b643963d"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 178, 96)           576       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 89, 96)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 85, 192)           92352     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 42, 192)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 38, 384)           369024    \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 19, 384)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 7296)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               3736064   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4201094 (16.03 MB)\n",
      "Trainable params: 4201094 (16.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ser_cnn_model = create_cnn_model((182,1), 96, 5, 0.4)\n",
    "ser_cnn_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T03:07:40.416685Z",
     "start_time": "2024-03-29T03:07:40.310056Z"
    }
   },
   "id": "b4b57608cfd0dd09"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1154/1154 [==============================] - 30s 26ms/step - loss: 1.2935 - accuracy: 0.4740 - val_loss: 1.1138 - val_accuracy: 0.5542 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "1154/1154 [==============================] - 32s 28ms/step - loss: 1.0936 - accuracy: 0.5617 - val_loss: 1.1032 - val_accuracy: 0.5516 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "1154/1154 [==============================] - 34s 29ms/step - loss: 0.9996 - accuracy: 0.6005 - val_loss: 1.0065 - val_accuracy: 0.5966 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "1154/1154 [==============================] - 35s 31ms/step - loss: 0.9221 - accuracy: 0.6339 - val_loss: 0.9375 - val_accuracy: 0.6265 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "1154/1154 [==============================] - 35s 30ms/step - loss: 0.8432 - accuracy: 0.6680 - val_loss: 0.9531 - val_accuracy: 0.6333 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "1154/1154 [==============================] - 34s 30ms/step - loss: 0.7714 - accuracy: 0.6970 - val_loss: 0.9102 - val_accuracy: 0.6492 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "1154/1154 [==============================] - 35s 30ms/step - loss: 0.6916 - accuracy: 0.7296 - val_loss: 0.9188 - val_accuracy: 0.6549 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "1154/1154 [==============================] - 35s 30ms/step - loss: 0.6390 - accuracy: 0.7526 - val_loss: 0.9240 - val_accuracy: 0.6674 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "1154/1154 [==============================] - 34s 30ms/step - loss: 0.5734 - accuracy: 0.7756 - val_loss: 0.8955 - val_accuracy: 0.6781 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "1154/1154 [==============================] - 35s 31ms/step - loss: 0.5327 - accuracy: 0.7946 - val_loss: 0.9634 - val_accuracy: 0.6785 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "1154/1154 [==============================] - 34s 30ms/step - loss: 0.4873 - accuracy: 0.8124 - val_loss: 0.9626 - val_accuracy: 0.6884 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "1154/1154 [==============================] - 35s 30ms/step - loss: 0.4428 - accuracy: 0.8250 - val_loss: 0.9941 - val_accuracy: 0.6943 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "1154/1154 [==============================] - 35s 30ms/step - loss: 0.4391 - accuracy: 0.8326 - val_loss: 1.0444 - val_accuracy: 0.6978 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "1154/1154 [==============================] - 36s 31ms/step - loss: 0.3930 - accuracy: 0.8526 - val_loss: 1.0553 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "1154/1154 [==============================] - 34s 30ms/step - loss: 0.3745 - accuracy: 0.8608 - val_loss: 1.0848 - val_accuracy: 0.7041 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "1154/1154 [==============================] - 35s 30ms/step - loss: 0.3540 - accuracy: 0.8663 - val_loss: 1.1283 - val_accuracy: 0.6998 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "1154/1154 [==============================] - 36s 31ms/step - loss: 0.3323 - accuracy: 0.8740 - val_loss: 1.2184 - val_accuracy: 0.6945 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "1154/1154 [==============================] - 35s 30ms/step - loss: 0.3078 - accuracy: 0.8840 - val_loss: 1.1453 - val_accuracy: 0.7106 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "1154/1154 [==============================] - 34s 29ms/step - loss: 0.3002 - accuracy: 0.8869 - val_loss: 1.2032 - val_accuracy: 0.7095 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "1154/1154 [==============================] - 35s 30ms/step - loss: 0.2845 - accuracy: 0.8936 - val_loss: 1.2623 - val_accuracy: 0.7118 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\n",
    "ser_cnn_model_history = ser_cnn_model.fit(x_train, y_train, batch_size=32, epochs=20, validation_data=(x_test, y_test), callbacks=[rlrp])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T03:20:11.839338Z",
     "start_time": "2024-03-29T03:08:43.333468Z"
    }
   },
   "id": "6cae29128eac10b1"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 3s 11ms/step - loss: 1.2623 - accuracy: 0.7118\n",
      "Accuracy of model on test data :  71.18405103683472 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of model on test data : \", ser_cnn_model.evaluate(x_test, y_test)[1] * 100, \"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T03:20:20.707687Z",
     "start_time": "2024-03-29T03:20:17.499484Z"
    }
   },
   "id": "513fc87fa1671a17"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf_env/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "ser_cnn_model.save('new-tuned-ser-cnn-model.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T03:20:30.279858Z",
     "start_time": "2024-03-29T03:20:30.234055Z"
    }
   },
   "id": "453abb98f08fbe3e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "aedfff481a992993"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
